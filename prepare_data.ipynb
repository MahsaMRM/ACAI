{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#run this in command line\n",
    "# !python acai.py \\\n",
    "# --train_dir=TEMP \\\n",
    "# --latent=16 --latent_width=2 --depth=16 --dataset=fire_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tqdm import trange, tqdm\n",
    "import random\n",
    "import os, re\n",
    "from PIL import Image\n",
    "from create_datasets import _encode_png, _save_as_tfrecord, _int64_feature, _bytes_feature  \n",
    "from sklearn.model_selection import train_test_split\n",
    "from acai import ACAI\n",
    "from lib import data\n",
    "import functools, math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_images_list(input_dir):\n",
    "    \n",
    "    ''' \n",
    "    Returns the list of images in input_dir           \n",
    "    '''   \n",
    "    images_list = [os.path.join(input_dir, image_name) for image_name in os.listdir(input_dir)]\n",
    "    return images_list\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_images(input_dir, output_dir, cropbox=(0, 0, 700, 600)):\n",
    "    \n",
    "    ''' \n",
    "    This function cuts the text at the bottom of noun project symbols \n",
    "    and covert the 3 channels to 1 \n",
    "    \n",
    "    kwargs:\n",
    "    cropbox= (left, upper, right, lower) is the symbols frame\n",
    "    boundry box, anything outside of this box is cut out           \n",
    "    '''\n",
    "    \n",
    "    images_path = get_images_list(input_dir)\n",
    "#     print(images_path)\n",
    "    \n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "        \n",
    "    for img in images_path:    \n",
    "    #     (left, upper, right, lower)\n",
    "        crop_box=cropbox\n",
    "        original_img=Image.open(img)\n",
    "        cropped_img=original_img.crop(crop_box)\n",
    "        background=Image.new(\"RGB\", cropped_img.size, (255, 255, 255))\n",
    "        background.paste(cropped_img, mask=cropped_img.split()[3]) # 3 is the alpha channel\n",
    "#     converting channel 3 to 1:\n",
    "        converted_img = background.convert(\"L\")\n",
    "        converted_img.save(output_dir+'{}'.format(os.path.basename(os.path.normpath(img))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare_images('./images/leaf-fire/', './images/leaf-fire_channel1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(image_path, resizing_w_h):\n",
    "    ''' \n",
    "    Reads and returens image in PIL.Image.Image format\n",
    "    \n",
    "    kwargs:\n",
    "\n",
    "    resizing_w_h:images are resized to have the height and width of resizing_w_h   \n",
    "    ''' \n",
    "    original_img = Image.open(image_path)\n",
    "    resized_img = original_img.resize((resizing_w_h, resizing_w_h))\n",
    "    return resized_img\n",
    "\n",
    "\n",
    "def get_labels(image_path, image_type):\n",
    "    \n",
    "    ''' \n",
    "    Reads the image name and returns a number as its label\n",
    "    \n",
    "    kwargs:\n",
    "\n",
    "    image_type: if font: it gets the font letter and returns a number between 1-28 \n",
    "    '''\n",
    "    \n",
    "    str_label=re.search('_(.+?).png', os.path.basename(os.path.normpath(image_path))).group(1)\n",
    "    \n",
    "    if image_type=='font':\n",
    "        return ord(str_label) - 64\n",
    "        \n",
    "    elif image_type=='symbol':\n",
    "        \n",
    "        if str_label =='fire':\n",
    "\n",
    "            return 0\n",
    "            \n",
    "        elif str_label == 'leaf':\n",
    "\n",
    "            return 1\n",
    "        \n",
    "def get_images_arr(input_dir, resizing_w_h, image_type='symbol'):\n",
    "    \n",
    "    ''' \n",
    "    Returns the images and their labels formatted in two numpy arrays with np.uint8 type\n",
    "    '''\n",
    "             \n",
    "    imgdirs = get_images_list(input_dir)\n",
    "    random.shuffle(imgdirs)\n",
    "    \n",
    "    images_arr=np.array([np.reshape(np.array(read_img(img, resizing_w_h), dtype=np.uint8),\n",
    "                                     (resizing_w_h,resizing_w_h,1)) for img in imgdirs[:]])\n",
    "    labels=[get_labels(img, image_type) for img in imgdirs[:]]\n",
    "\n",
    "    labels_arr=np.array(labels, dtype=np.uint8)\n",
    "    \n",
    "    return images_arr, labels_arr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data(image_dir, resizing_w_h=28, test_size=.25):\n",
    "    \n",
    "    ''' \n",
    "    Gets the images piexls and their arrays, returns dictionaries of labels arrays and\n",
    "    tensors of images pixels (ecnodes images arrays to tensorflow images)\n",
    "    for both test and train sets\n",
    "\n",
    "    kwargs:\n",
    "    test_size: the portion images split for test set\n",
    "    '''\n",
    "    \n",
    "    images, lables=get_images_arr(image_dir, resizing_w_h)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(images, lables,\n",
    "                                                        test_size=test_size)\n",
    "\n",
    "    test_set = {'images': X_train,\n",
    "                'labels': y_train}\n",
    "    train_set = {'images': X_test,\n",
    "                'labels': y_test}\n",
    "\n",
    "    train_set['images'] = _encode_png(train_set['images'])\n",
    "    test_set['images'] = _encode_png(test_set['images'])\n",
    "    \n",
    "    return dict(train=train_set, test=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOADERS = [\n",
    "    ('fire_leaf', prepare_data)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing fire_leaf\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building records: 100%|██████████| 300/300 [00:00<00:00, 14995.55it/s]\n",
      "Building records: 100%|██████████| 100/100 [00:00<00:00, 6800.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving dataset: ./data/fire_leaf-test.tfrecord\n",
      "Saving dataset: ./data/fire_leaf-train.tfrecord\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# storing the data as as TFRecord (a sequence of binary strings)\n",
    "\n",
    "for name, loader in LOADERS:\n",
    "    print 'Preparing', name\n",
    "    datas = loader('./images/leaf-fire_channel1/')\n",
    "    for sub_name, data in datas.items():\n",
    "        \n",
    "         TFRecord file stores your data as \n",
    "        _save_as_tfrecord(data, '%s-%s' % (name, sub_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
